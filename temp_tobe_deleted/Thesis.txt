Assessing comment semantics by applying NLP based Feature location technique
============================================================================

Abstract
---------

In computer science and software engineering in particular source code is the core which
decides the success of a software system. Understanding and analyzing a larger software system becomes challenging if adequate quality is not built in the code, it is important for software maintenance. Code comments plays a major role here, main source for documenttion and helps to understand the system easily than knowing the code which is often complex. Comments contains vital information about a software system but deveoperes often neglects commenting the code and fails to keep it up to date. Many literatures on source code comments exists today whcih addresses how to use commenets to detect code clone, detect vulneravbilities, feature location adn so on. So it is important to have meaningful comments which semantically  matches the source code. Although there are approaches to evauate code comments adn quality exists, they ignore the comment semantics or how close the comments with its code or they focus on the comment quantity.
This research work is going to assess the comment semantics, how close is the comment with the source code, does the comment accurtley reflect the feature it implements. Freature location is the technique going to be used to assess the comment. NLP based feature location 'Latent Semantic Indexing' technique is going to be applied on code comments to locate the feature. Succeful navigation indicates project has good quality comments semantically matches with the source code. Low accuracy of feature  location shows project requires improvemtn in the code comments. This approach is going to extend further to assess whether the code or the comments has more accuracy in locating the feature.

Introduction (background / research context)
--------------------------------------------
Software systems meant to run longer so maintenance is part of it. Its quality, security and design are often
reviewed, analysed and refined through out the product life span. For software maintenance and to ensure code quality it is essential to address code plagiarism, identify feature similarity, find vulnerabilities, predict test failures etc and address those. But
understanding and analyzing a large software code is highly challenging and if the system is legacy it becomes more complex, time consuming and budgetary. There have been various researches happening in this field to ease this process. Researchers keep exploring new methods and tools hence continuously contributing to the software engineering community. 

Understanding the source code adn its features are crucial in maintaining the software. Code is usually written once by a person but read multiple times by many. Comments allow developers to understand the code much faster and easy rather than going through code which if often complex. Usually a significant part of the code contains comments written adn evolved over the time. Researches shows that code with comment is easy to understand if it is written properly without losing the code semantics. Whether it is inspected manually or with programs comments are valuable entity that plays the role in software maintanance. There are many literatures work with comments to locate features, to detect vulnerabilities, to assess its quality and to detect code clone etc. Its usability is endless, so it is essenetial to have good quality comments in place. At times it is not the quantity or the number of comments vs code ratio matters, rather the quality of comments, how sematically close these comments with the code and features matters the most.

This research explores a methodology to assess the comment semantics. This will judge how semantically close these comments with the source code and program features. Result of this analysis will recommend if project requires any improvements in comments. Feature location technique is going to be used in the assessment. NLP based feature location technique Latent Semantic Indexing is going to be used for the analysis.


Research Aim
==============
   Semantic assessment of comments to find Feature Location by applying LSM and VSM techniques


Research Objectives
=======================
	
- Assess whether the artifacts or the comments have more accuracy in locating the feature 
    Artifacts or artifacts with comments are widely used in feature location techniques. Novelty of this research is to assess whether comments or artifacts have more accuracy in feature location when applied NLP based feature location techniques.
	
- Assess the quality of comments to semantically match the source code
    Most times it is the quality of comments that is semantically how close the comments with the source code matters than its quantity. 
	It helps the develpers in trouble shooting and understand the system faster. Good comments gives more accurate feature location results.
	This researh is going to assess the semantic aspect of comments with the code in locating feature.
	
- Assess whether removing code-commented improves the quality of the Feature Location
    It is very commen to have commented code in a software program. Often developers keep the commented code for future reference, temporarily commented or they might have forgot to remove it altogether. This research is going to assess how the commented code impacts teh feature lotion result. Does it going to improve the accuracy or will that impact the result negatively.
    
- Determine if a project requires improvements in comments
	A software program is a mixture of code and comments. Comments may appear anywhere in the code line comment, docuement comment, method comments etc. When there are comments in the code visual inspection might give a feel of adequate comments but that may not be the truth. A programmatic assessment gives more accurate result. With applying NLP based feature location techniques on comments is going to find out whether comments needs improvement or not.

- Explore Feature location techniques LSI or VSM has more accuracy when working with comments. 
	LSI and VSM are widely used feature loation techniques. This can be applied on comments, artifacts or together to loacate the feature. This research is going to explore which one results more accurate feature location when working with comments. 

During a detailed scrutiny of the content and the amount of research involved it was evident that the research can be completed only if adequate time is available. Limited semester timelines and any unforeseen external events may have an impact on the research scope.

Research Methodology
=====================
The proposed research will be following Qualitative methodology to fulfill the research
objectives. Primary goal of this research is to assess how semantcally close the comments are with the soure code and its usability in feature location. NLP based feature location technique 'Latent Semantic Indexing' and VSM are going to be used in this research. Comments and artefacts are processed individualy and together to find accurate featuer location for the query. This methodology is refined further to find answers for the research questions mentioned above. If comments alone is able to locate the feature in more accurate that shows project is having a quality comment and it is semantically matches the source code. 

Various programming exercises needs to be conducted in each stage of the analysis to reach the required outcome. Developed program needs to be tested and validated against the gold set. A github project has been identified as a gold set to validate the program.  (https://github.com/masud-technope/BLIZZARD-Replication-Package-ESEC-FSE2018/tree/master). Once the program is validated and tested against the gold set it will then be applied on various open source projects. Following popular open source projects have been identified for this exercise. 

   Antlr4 : https://github.com/antlr/antlr4/tree/master/runtime/Java/src/org/antlr/v4
   Selenium: https://github.com/SeleniumHQ/selenium/tree/trunk/java/client/src/com/thoughtworks/selenium
   Apache-Groovy : https://github.com/apache/groovy/tree/master/src/main/java/org/codehaus/groovy
   Spring Kafka : https://github.com/spring-projects/spring-kafka/tree/master/spring-kafka/src/main/java/org/springframework/kafka
   Cloudfoundry Uaa : https://github.com/cloudfoundry/uaa/tree/develop/server/src/main


Following are various phases of implementations. Phases are implemented as in indepenedt project like micro services and each phase's output is keyin as input to the next phase. This modular design gives loose coupling of components that enables indipendent developemtn, testing and integration efforts.

Phase 1) Java Parser, Parsing java files and creating documents
  JavaParser libray is used to parse the java source files. Each file is parsed to extract the comments - line comment, method comments, document comments all identified in this step. This data goes to NLP filtering such as tokenizer, stop word removal and finally creates a document with all these fields. Various documents are created in this phase such as document with comments, document with artificacts, document after removing code-commented. These diffrent documents are used in the phase2 and phase 4 for processing and evalidation.
  
Phase 2) Processing, Applying Feature Location Technique LSI and VSM 
   Output of Javaparser module is the input to this phase. Documents created by Phase1 are processed using LSI and VSM Feature location techniques to find the most matching document. This processing is further refined for various combinaion of documents such as document with comments, documents with comments and artificacts, docuement after removing code-commented.

Phase 3) Program Validation, Validating the program against gold set
   Most matching document for the given query is the feature location result. This is validated against the gold set to ensure the program functions as expected. Result from previous steps based on each document is validated in this phase with gold set to qualify the program for the next phase.

Phase 4) Evaluation, Evaluation of comment semantics and research questions.
	This is the final phase where comment semantics and various research questions are answered. Qualified program from the previous phase is applied on identified open source projects in addition to the gold set to assess the code comments and feature location. These evaluation results will answer all those research questions.


Research will be conducted in a series of phases. Learning and data gathering phase
is the first where deep analysis of latest literatures and technology are carried out. Various literatures in the field of
featuer loation and code comments are reviewed to learn more about this researched items. Finding the right gold set to validate the program is the next task. Gold set needs to be finalized and its readyness is important for the project validation. Next phase is the development phase where the program is developed to find the feature location for the given search string using code and comments. After the initial validation same will be tested against the gold set to assess the program quality. Once verified a few open source project will be assessed using this program to know whether it has meaningful comments in place or it reqires improvements. This will be iterated on various projects to assess its qiality. Below digram shows the basic flow of research methodology.

Timeline and Reference
======================

Work Plan:
-----------
Research project spans over four months, starting from January 2021 till mid May. A research execution
plan is set with the help of WBS and Gantt chart to meet the time lines.
Project execution progresses in various phases. Learning and literature review phase is the first
one where deep analysis of latest literatures and technology are carried out. Various literatures in the field of
featuer loation and code comments are reviewed to learn more about this researched items. Documenting these would benefit and build
confidence to execute further phases. Finding the right gold set to validate the program is the next task. Gold set needs to be finalized and its readyness is important for the project validation. Only afetr the development phase can begin where the program is developed to find the feature location for the given search string using code and artifacts.

In this development phase first part is the code parser. JavaParser library will be used to parse the java fource files and that will create  documents from it. Processing phase followes to that where this document is processed to find feature location. Feature loaction techniques LSI and VSM are applied on docunents to locate the feature. This leads to the program validation phase, after the initial validation the program then be tested against the gold set to assess its readyness and quality. 

Result evaluation and the thesis submission are the final two phases of the project. Results from the previous phase is evaluated here
by applying the program over identfied open source prijects. Results are collected, reviewed and prepare the matrices to conclude the research questions. Final report writing also needs to be started in this phase. Documentation is an ongoing tasks through out these phases so no need to allocate more time in the submission phase. Final report then reviewed and submitted to the professor before the submission date.

Below detailed the work breakdown structure (WBS) of the research project.


	a WBS pic
	
	
A Gantt chart has been prepared based on this WBS. This chart is the visual representation of the wbs breakdown that shows when a task is starting, when it finishes and also shows overlapping tasks.

  Gantt chart here
  
Current Progress of this research
==================================
- literature reviews comepleted
	Following literates are reviewed and gained knwoledge on latest state of the art in the field of comments procesing adn feature location. Research questions fine tuned based on the inputs from these papers.

    https://ieeexplore.ieee.org/document/8766656 (Location Prediction Based on Comment Analysis - 2019)
	https://ieeexplore.ieee.org/document/6613836 (Quality analysis of src code comments - 2013)
	https://ieeexplore.ieee.org/document/8506550  (Semantic Clone Detection: Can Source Code Comments Help? - 2018)
	https://ieeexplore.ieee.org/document/8920024 (Deep Code-Comment Understanding and Assessment - 2019)
	https://ieeexplore.ieee.org/document/7820211 (Using Natural Language Processing to Automatically Detect Self-Admitted Technical Debt - 2017)
	https://ieeexplore.ieee.org/document/8809910 (Learning Code Context Information to Predict Comment Locations)

- Identified the gold set  https://github.com/masud-technope/BLIZZARD-Replication-Package-ESEC-FSE2018/tree/master/

This gold set is extracted from the github project 'BLIZZARD-Replication-Package-ESEC-FSE2018' which is basically a research paper 'Improving IR-Based Bug Localization with Context-Aware Query Reformulation' by Masud Rahman. In this paper he has introduced a new technique BLIZZARD-- that auto localizes bugs from source using query reformulation and information retrieval. This projects uses query based feature location to locate the defect this data is available under Baseline and Goldset directories. This is going to be treated as a gold set for this research program and will be validated against that.

Baseline/Query/ecf.txt contains various queries. Each query is labaled with a number e.g 112599, 119206. These numbers are important as the query result is going to have the same number. This is the query associated with query id 112599 "XMPP Room subject updated xmpp chat updated remotely xmpp server title room updated dynamically" and its result is going to be in 11259.txt file.
Corpus/ecf contains java files. Original file names are renamed to numbers. eg. 100.java, 1001.java etc. Its number to original filename
mapping is available in XXxX.index fil.
Goldset/ecf is having the query ressult and it is mapped according to the query number. e.g 112599.txt file is the query result of the same query number. Its result is XMPPChatRoomContainer.java which is mapped in XXxX.index and the file name is yyyy.java (need to find out)

- Open source projects have been identified for the evaluation
	Popular open source projects written in java are identified for the theses evaluation in addition to the gold set. Research questions are answered here by running the software programs against these projects and evaluating the results.
	
   Antlr4 : https://github.com/antlr/antlr4/tree/master/runtime/Java/src/org/antlr/v4
   Selenium: https://github.com/SeleniumHQ/selenium/tree/trunk/java/client/src/com/thoughtworks/selenium
   Apache-Groovy : https://github.com/apache/groovy/tree/master/src/main/java/org/codehaus/groovy
   Spring Kafka : https://github.com/spring-projects/spring-kafka/tree/master/spring-kafka/src/main/java/org/springframework/kafka
   Cloudfoundry Uaa : https://github.com/cloudfoundry/uaa/tree/develop/server/src/main

- JavaParser - Parsing java files and creating documents
	Initial phase of the program is completed. A program is written to parse the jave files using JavaParser library. Java files are parsed using the library then extracted the comments from the files using getAllContainedComments() API. These comments are tokenized, removed stop words then added as a 'comment' field into the document.


  
Ethical Issues
==============
- Following all primary ethics but not limited to have been considered in the research.
- All reference materials and quotes are cited appropriately
- Respect and dignity has given for each researcher in the filed of source code analysis
- Adequate level of confidentiality of the research is maintained
- There are no affiliation, funding or grands provided for this research
- This research will be conducted for the academic purpose associated with CIT only.
- There are no misleading or biased information present in the research
- Research is adhered to the data protection rule, GDPR.


Bibliography
============









